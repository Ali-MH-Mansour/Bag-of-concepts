{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ali-MH-Mansour/Bag-of-concepts/blob/main/Code/Bag_of_concepts_Vdhya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe8E2O_7iyQX"
      },
      "source": [
        "## **Connect to the Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I0ZTb-sqxH7",
        "outputId": "7ea459b1-3255-4b0b-aff3-724e25bb5aa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gge2NxpEmGsT"
      },
      "source": [
        "# Functions for the data set preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOH5gupuRUiH",
        "outputId": "2ce8c62b-4472-4ddf-fe62-a1d051e2389d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Collecting soyclustering\n",
            "  Downloading soyclustering-0.2.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: numpy>=1.1 in /usr/local/lib/python3.7/dist-packages (from soyclustering) (1.19.5)\n",
            "Installing collected packages: soyclustering\n",
            "Successfully installed soyclustering-0.2.0\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from numpy import array \n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter \n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "#-------------------------------------------------------------------------------\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize, pos_tag\n",
        "#-------------------------------------------------------------------------------\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\d+' , '', text)\n",
        "    text = remove_punctuation(text)\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)\n",
        "    tokens = toknizing(text)\n",
        "    pos_map = {'J': 'a', 'N': 'n', 'R': 'r', 'V': 'v'}\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    lemmatiser = WordNetLemmatizer()\n",
        "    tokens = [lemmatiser.lemmatize(t.lower(), pos=pos_map.get(p[0], 'v')) for t, p in pos_tags]\n",
        "    return tokens\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "def remove_punctuation(text):\n",
        "     punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^+&*_~'''\n",
        "     no_punct = \"\"\n",
        "     for char in text:\n",
        "        if char not in punctuations:\n",
        "            no_punct = no_punct + char\n",
        "     return no_punct\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "def toknizing(text):\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = word_tokenize(text)\n",
        "  result = [i for i in tokens if not i in stop_words]\n",
        "  return result\n",
        "#-------------------------------------------------------------------------------\n",
        "def cosine_distance(u, v):\n",
        "  return np.dot(u, v) / (math.sqrt(np.dot(u, u)) * math.sqrt(np.dot(v, v)))\n",
        "#-------------------------------------------------------------------------------\n",
        "!pip install soyclustering\n",
        "from soyclustering import SphericalKMeans\n",
        "from scipy.sparse import csr_matrix\n",
        "#-------------------------------------------------------------------------------\n",
        "def spherical_kmeans(n_clusters_, list_of_words_vectors,sim_digree):\n",
        "  embeddings_matrix_csr = csr_matrix(list_of_words_vectors)\n",
        "  spherical_kmeans = SphericalKMeans( max_similar=sim_digree, init='similar_cut', \n",
        "      n_clusters = n_clusters_)\n",
        "  labels = spherical_kmeans.fit_predict(embeddings_matrix_csr)\n",
        "  centers = spherical_kmeans.cluster_centers_\n",
        "  return labels , centers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj8ww4vWj5BX"
      },
      "source": [
        "##Data sets Downolad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rnb1TFbGkhct",
        "outputId": "2efeabb2-7089-4172-daca-7ac506b2ad8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dc8b0081-fdbd-4208-8703-171680ce9e3b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc8b0081-fdbd-4208-8703-171680ce9e3b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc8b0081-fdbd-4208-8703-171680ce9e3b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc8b0081-fdbd-4208-8703-171680ce9e3b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           class                                           document\n",
              "0           tech  tv future in the hands of viewers with home th...\n",
              "1       business  worldcom boss  left books alone  former worldc...\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3          sport  yeading face newcastle in fa cup premiership s...\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve..."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "BBC_file_path=\"/content/drive/........./Data/bbc-text.csv\"\n",
        "data_DF = pd.read_csv(BBC_file_path)\n",
        "\n",
        "# rename columns\n",
        "data_DF.columns.values[0] = \"class\"\n",
        "data_DF.columns.values[1] = \"document\"\n",
        "\n",
        "data_DF.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tZVrjJlmGctt",
        "outputId": "ac315cce-3470-43b8-9ad7-8adf5acfc8c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-156c915e-2122-4c77-a881-3c560f86b546\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>future hand viewer home theatre system plasma ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>worldcom bos leave book alone former worldcom ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>tiger wary farrell gamble leicester say rush m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>yeading face newcastle cup premiership side ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>ocean twelve raid box office ocean twelve crim...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-156c915e-2122-4c77-a881-3c560f86b546')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-156c915e-2122-4c77-a881-3c560f86b546 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-156c915e-2122-4c77-a881-3c560f86b546');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   class                                           document\n",
              "0      0  future hand viewer home theatre system plasma ...\n",
              "1      1  worldcom bos leave book alone former worldcom ...\n",
              "2      2  tiger wary farrell gamble leicester say rush m...\n",
              "3      2  yeading face newcastle cup premiership side ne...\n",
              "4      3  ocean twelve raid box office ocean twelve crim..."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Factorize class names to numbers\n",
        "data_DF['class'] = pd.factorize(data_DF['class'])[0]\n",
        "data_DF['document'] = data_DF.document.apply(lambda x: ' '.join(preprocess_text(x)))\n",
        "data_DF.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwKMpUBNjsKT"
      },
      "source": [
        "## Train Fasttext model on BBC data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U6UbrjtHp0iy"
      },
      "outputs": [],
      "source": [
        "# Train fast text model on your dataset\n",
        "import gensim\n",
        "from gensim.models import FastText\n",
        "documents_as_list = data_DF['document'].tolist()\n",
        "doc_as_tokens =[]\n",
        "for doc in documents_as_list:\n",
        "  doc_as_tokens.append(doc.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vt4z_IiKtO1G"
      },
      "outputs": [],
      "source": [
        "model = FastText(doc_as_tokens, size=300, window=15, min_count=1, workers=4,sg=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3vs_X3xlJGb"
      },
      "source": [
        "## Create Dictionary of words "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "81aCahTnKf61"
      },
      "outputs": [],
      "source": [
        "dic_w_v = {}\n",
        "all_doc_emb = []\n",
        "for doc in doc_as_tokens:\n",
        "  doc_emb = []\n",
        "  for w in doc:\n",
        "    try :\n",
        "      emb = model.wv[w]\n",
        "      doc_emb.append(emb)\n",
        "      dic_w_v.update({w : emb})\n",
        "    except: \n",
        "      continue;\n",
        "  all_doc_emb.append(doc_emb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSThZ7Xwlk8D"
      },
      "source": [
        "## Clustering the words (concepts extraction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ITdUoveQKEub"
      },
      "outputs": [],
      "source": [
        "list_of_words_vectors = list(dic_w_v.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9y9uRZfH5fY",
        "outputId": "6a396c09-642a-4739-c7e3-1cd01300bd85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The clusters details Counter({54: 274, 24: 255, 206: 245, 74: 219, 58: 219, 69: 212, 145: 207, 113: 203, 97: 192, 276: 191, 148: 191, 71: 191, 195: 191, 2: 185, 233: 185, 280: 183, 179: 176, 189: 172, 25: 172, 141: 169, 264: 168, 102: 168, 297: 167, 57: 165, 35: 163, 17: 161, 135: 159, 39: 156, 60: 155, 126: 154, 48: 154, 222: 152, 36: 151, 117: 148, 244: 147, 118: 146, 254: 144, 105: 143, 63: 141, 227: 141, 187: 141, 286: 140, 89: 140, 75: 139, 109: 139, 270: 138, 267: 134, 284: 134, 14: 133, 4: 133, 295: 132, 186: 132, 178: 131, 192: 131, 98: 127, 77: 127, 131: 126, 293: 126, 46: 125, 99: 124, 240: 123, 27: 123, 299: 123, 292: 122, 261: 122, 164: 121, 210: 121, 31: 120, 66: 120, 139: 120, 49: 118, 161: 117, 175: 117, 155: 117, 230: 116, 91: 116, 262: 116, 165: 115, 176: 115, 294: 115, 268: 112, 138: 111, 211: 111, 228: 111, 253: 110, 237: 109, 90: 108, 81: 107, 44: 107, 88: 106, 266: 105, 10: 104, 160: 104, 41: 104, 289: 104, 291: 102, 120: 101, 128: 100, 80: 100, 144: 100, 217: 100, 209: 100, 62: 100, 204: 99, 282: 99, 143: 99, 245: 99, 283: 98, 23: 97, 127: 97, 277: 96, 205: 96, 232: 96, 255: 96, 70: 95, 112: 95, 12: 94, 129: 94, 40: 94, 68: 94, 174: 93, 162: 93, 290: 92, 250: 92, 20: 91, 193: 90, 229: 90, 83: 89, 201: 89, 6: 88, 202: 88, 154: 88, 278: 88, 185: 87, 42: 87, 287: 86, 167: 85, 121: 84, 216: 84, 53: 83, 79: 83, 172: 83, 157: 82, 231: 82, 101: 81, 188: 81, 275: 79, 55: 79, 86: 78, 100: 77, 111: 77, 43: 75, 246: 75, 78: 75, 273: 75, 26: 72, 3: 72, 208: 72, 5: 72, 177: 71, 30: 71, 224: 70, 169: 69, 239: 69, 285: 69, 248: 69, 163: 67, 50: 66, 173: 66, 168: 66, 33: 66, 226: 65, 64: 65, 52: 64, 220: 64, 197: 64, 124: 64, 207: 64, 95: 63, 92: 63, 107: 63, 150: 62, 125: 62, 61: 62, 194: 61, 114: 61, 260: 61, 252: 60, 269: 59, 219: 59, 8: 59, 281: 59, 263: 58, 59: 58, 87: 58, 72: 58, 56: 58, 298: 57, 271: 56, 76: 56, 181: 56, 243: 55, 180: 54, 152: 54, 257: 54, 96: 54, 184: 54, 21: 53, 85: 52, 146: 52, 225: 52, 73: 52, 84: 52, 235: 51, 191: 51, 265: 50, 238: 49, 274: 49, 122: 49, 45: 49, 149: 49, 182: 49, 37: 47, 22: 47, 215: 46, 171: 46, 19: 46, 147: 46, 103: 45, 140: 45, 200: 45, 142: 44, 115: 44, 170: 43, 241: 42, 104: 41, 203: 41, 196: 41, 199: 41, 183: 41, 133: 40, 34: 40, 130: 40, 136: 39, 247: 39, 18: 39, 249: 39, 213: 38, 47: 37, 156: 36, 198: 36, 15: 35, 221: 35, 11: 34, 166: 34, 94: 34, 38: 34, 296: 33, 223: 32, 51: 32, 153: 32, 67: 32, 234: 31, 134: 30, 151: 30, 9: 30, 13: 29, 218: 28, 159: 27, 106: 26, 236: 25, 259: 24, 137: 24, 123: 24, 279: 23, 82: 22, 272: 22, 93: 22, 288: 21, 119: 21, 110: 21, 29: 19, 212: 18, 16: 17, 28: 16, 251: 16, 7: 16, 116: 16, 242: 16, 0: 13, 256: 12, 214: 11, 132: 10, 258: 9, 32: 7, 190: 2, 108: 2, 1: 1, 65: 1, 158: 1}) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# number of clusters\n",
        "K_clusters= 300\n",
        "sim_digree=0.4\n",
        "######### Clustering\n",
        "labels , centers = spherical_kmeans(K_clusters , list_of_words_vectors, sim_digree)\n",
        "print(\"The clusters details\", Counter(labels), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NA1crRuZT5E"
      },
      "source": [
        "# Bag of weighted Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "869bhrJcim0p"
      },
      "source": [
        "### Documents vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EGzqNobbi5u-"
      },
      "outputs": [],
      "source": [
        "#خاص بحقيبة الكلمات الاصلية\n",
        "def BOC(embeddeings_document,alpha,centers):\n",
        "  concept_occurence = 0\n",
        "  ## intilize doc array\n",
        "  CF_vector = np.zeros(len(centers)).tolist()\n",
        "  for cnt in range(len(centers)):\n",
        "    for emb_word in embeddeings_document:\n",
        "      Wsim= cosine_distance(emb_word , centers[cnt])\n",
        "      if Wsim  > alpha:\n",
        "        concept_occurence = concept_occurence + 1 #for tf\n",
        "        CF_vector[cnt] = CF_vector[cnt] + 1;\n",
        "      else:\n",
        "        continue;    \n",
        "  if concept_occurence !=0:\n",
        "    for i in CF_vector:\n",
        "      i = i / concept_occurence  #count/\n",
        "  return CF_vector\n",
        "#-------------------------------------------------------------\n",
        "def CF_IDF_BOC(documents_embeddings , alpha , centers):\n",
        "  CFs = []\n",
        "  counter = 0\n",
        "  Df = np.zeros(len(centers)).tolist() # بطول العناقيد\n",
        "  for doc in documents_embeddings: \n",
        "    CF = BOC(doc , alpha , centers )\n",
        "    for i in CF: \n",
        "      if i > 0:\n",
        "        Df[counter] = Df[counter] + 1 #  i[M-1]\n",
        "      counter = counter+1\n",
        "    counter = 0\n",
        "    CFs.append(CF)\n",
        "  #########  calculate IDF\n",
        "  IDF=[]\n",
        "  for df in Df:\n",
        "    if df!=0:\n",
        "      N=len(documents_embeddings)\n",
        "      IDF.append( math.log10( (N+1) /df ) )\n",
        "    else:\n",
        "      IDF.append(0)  \n",
        "  #Calculate Cf-IDF\n",
        "  for i in range(N):\n",
        "    l=len(CFs[i])\n",
        "    for j in range(l):\n",
        "       CFs[i][j] = CFs[i][j] * IDF[j]  #cf*idf\n",
        "  return CFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ci2bgMM3NiDu"
      },
      "outputs": [],
      "source": [
        "# Thershold similarity values\n",
        "alpha = 0.4\n",
        "\n",
        "final_embeddings  = CF_IDF_BOC(all_doc_emb , alpha , centers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKGo6cSoi9UP"
      },
      "source": [
        "##Train SVM for dataset calssification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2dag8kha4HBw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score\n",
        "#-------------------------------------------------------------------------------\n",
        "classes = data_DF['class'].tolist()\n",
        "x_train , x_test , y_train , y_test = train_test_split(final_embeddings , classes , test_size = 0.30 , random_state = 0)\n",
        "svm =  SVC(kernel='rbf', random_state=44).fit(x_train , y_train) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTG5Kjb2jlPU"
      },
      "source": [
        "##**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M2A-HjuAjkwf",
        "outputId": "0e069e8d-d70f-48ee-e5d8-5eed6f27f115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The micro average-weighted f1 score =  0.8667664670658682\n"
          ]
        }
      ],
      "source": [
        "y_pred=svm.predict(x_test)\n",
        "F1 = f1_score(y_test,y_pred, average=\"micro\")\n",
        "\n",
        "print(\"The micro average-weighted f1 score = \", F1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWoyF3_3jWQu",
        "outputId": "161dd8dc-7348-4773-fe79-739c4fa878f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 89,  13,   0,   5,  10],\n",
              "       [  1, 139,   2,   1,   9],\n",
              "       [  0,   0, 174,   0,   3],\n",
              "       [  1,   6,  16,  83,   3],\n",
              "       [  2,  25,  11,   2,  73]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa_s-at68gVi",
        "outputId": "fe4e0783-7cbb-473b-e5bc-68043c5eed8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.76      0.85       117\n",
            "           1       0.76      0.91      0.83       152\n",
            "           2       0.86      0.98      0.92       177\n",
            "           3       0.91      0.76      0.83       109\n",
            "           4       0.74      0.65      0.69       113\n",
            "\n",
            "    accuracy                           0.84       668\n",
            "   macro avg       0.85      0.81      0.82       668\n",
            "weighted avg       0.84      0.84      0.83       668\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Bag_of_concepts_Vdhya.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}